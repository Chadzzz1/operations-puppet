cluster: cache_text
cache::cluster: text
cache::lua_support: true
profile::base::enable_microcode: true
admin::groups:
  - perf-roots
  - varnish-log-readers
prometheus::node_exporter::collectors_extra:
  - qdisc
  - meminfo_numa
mtail::ensure: 'stopped'
# The contents of this hash control our DC->DC routing for varnish backend
# daemons.  There should be a key for every cache datacenter.  The values must
# be a core datacenter (eqiad or codfw), or at least must lead indirectly to
# a core datacenter when traversing the table recursively.  A loop between
# the two core datacenters is expected and normal here.  The only reason to
# edit this is to remove a datacenter from active service (due to fault or
# maintenance) by routing around it from the edge sites.
#
cache::route_table:
  eqiad: 'codfw'
  codfw: 'eqiad'
  ulsfo: 'codfw'
  esams: 'eqiad'
  eqsin: 'codfw'
cache::app_def_be_opts:
  port: 80
  connect_timeout: '3s'
  first_byte_timeout: '63s'
  between_bytes_timeout: '31s'
  max_connections: 1000
cache::app_directors:
  appservers:
    backends:
      eqiad: 'appservers.svc.eqiad.wmnet'
    #   codfw: 'appservers.svc.codfw.wmnet'
  api:
    backends:
      eqiad: 'api.svc.eqiad.wmnet'
    #   codfw: 'api.svc.codfw.wmnet'
  security_audit:
    backends:
      eqiad: 'appservers.svc.eqiad.wmnet'
      # codfw: 'appservers.svc.codfw.wmnet'
  appservers_debug:
    be_opts:
      max_connections: 20
    backends:
      eqiad: 'hassium.eqiad.wmnet'
      # codfw: 'hassaleh.codfw.wmnet'
  restbase_backend:
    be_opts:
      port: 7231
      max_connections: 5000
    backends:
      eqiad: 'restbase.svc.eqiad.wmnet'
      #codfw: 'restbase.svc.codfw.wmnet'
  cxserver_backend:
    be_opts:
      port: 8080
    backends:
      eqiad: 'cxserver.svc.eqiad.wmnet'
      codfw: 'cxserver.svc.codfw.wmnet'
  webserver_misc_static:
    backends:
      eqiad: 'bromine.eqiad.wmnet'
      codfw: 'vega.codfw.wmnet'
  bohrium:
    backends:
      eqiad: 'bohrium.eqiad.wmnet'
  labweb:
    backends:
      eqiad: 'labweb.svc.eqiad.wmnet'
  darmstadtium:
    be_opts:
      port: 81
      max_connections: 5
    backends:
      eqiad: 'darmstadtium.eqiad.wmnet'
  debmonitor:
    backends:
      eqiad: 'debmonitor1001.eqiad.wmnet'
      # codfw: 'debmonitor2001.codfw.wmnet' # Active/Passive setup
  labtestweb2001:
    backends:
      eqiad: 'labtestweb2001.wikimedia.org'
  labtestspice:
    be_opts:
      port: 6082
    backends:
      eqiad: 'labtestcontrol2001.wikimedia.org'
  labspice:
    be_opts:
      port: 6082
    backends:
      eqiad: 'labcontrol1001.wikimedia.org'
  etherpad1001:
    be_opts:
      port: 9001
    backends:
      eqiad: 'etherpad1001.eqiad.wmnet'
  eventstreams:
    be_opts:
      port: 8092
      max_connections: 25  # https://phabricator.wikimedia.org/T196553
    backends:
      eqiad: 'eventstreams.svc.eqiad.wmnet'
      codfw: 'eventstreams.svc.codfw.wmnet'
  contint1001:
    backends:
      eqiad: 'contint1001.wikimedia.org'
  graphite:
    backends:
      eqiad: 'graphite1001.eqiad.wmnet'
#     codfw: 'graphite2001.codfw.wmnet'
  krypton:
    backends:
      eqiad: 'krypton.eqiad.wmnet'
  labmon1001:
    backends:
      eqiad: 'labmon1001.eqiad.wmnet'
  netmon1002:
    backends:
      eqiad: 'netmon1002.wikimedia.org'
  netmon1003:
    backends:
      eqiad: 'netmon1003.wikimedia.org'
  netmon2001:
    backends:
      eqiad: 'netmon2001.wikimedia.org'
  noc:
    backends:
      eqiad: 'mwmaint1001.eqiad.wmnet'
      codfw: 'mwmaint2001.codfw.wmnet'
  performance:
    backends:
      eqiad: 'webperf1001.eqiad.wmnet'
      codfw: 'webperf2001.codfw.wmnet'
  dbtree:
    backends:
      eqiad: 'terbium.eqiad.wmnet'
  gerrit:
    backends:
      eqiad: 'cobalt.wikimedia.org'
      # codfw: 'gerrit2001.wikimedia.org'
  phabricator:
    backends:
      eqiad: 'phab1001.eqiad.wmnet'
      # codfw: 'phab2001.codfw.wmnet'
  phab_aphlict:
    be_opts:
      port: 22280
      max_connections: 1000
    backends:
      eqiad: 'phab1001-aphlict.eqiad.wmnet'
      # codfw: 'phab2001-aphlict.codfw.wmnet'
  planet:
    backends:
      eqiad: 'planet1001.eqiad.wmnet'
      codfw: 'planet2001.codfw.wmnet'
  puppetboard:
    backends:
      eqiad: 'puppetboard1001.eqiad.wmnet'
      codfw: 'puppetboard2001.codfw.wmnet'
  pybal_config:
    backends:
      eqiad: 'puppetmaster1001.eqiad.wmnet'
      codfw: 'puppetmaster2001.codfw.wmnet'
  releases:
    backends:
      eqiad: 'releases1001.eqiad.wmnet'
      codfw: 'releases2001.codfw.wmnet'
  releases_jenkins:
    backends:
      eqiad: 'releases1001.eqiad.wmnet'
  ruthenium:
    be_opts:
      port: 8001
    backends:
      eqiad: 'ruthenium.eqiad.wmnet'
  rutherfordium:
    backends:
      eqiad: 'rutherfordium.eqiad.wmnet'
  thorium:
    backends:
      eqiad: 'thorium.eqiad.wmnet'
  ununpentium:
    backends:
      eqiad: 'ununpentium.wikimedia.org'
  mendelevium:
    backends:
      eqiad: 'mendelevium.eqiad.wmnet'
  logstash_director:
    backends:
      eqiad: 'kibana.svc.eqiad.wmnet'
  wdqs_director:
    backends:
      eqiad: 'wdqs.svc.eqiad.wmnet'
      codfw: 'wdqs.svc.codfw.wmnet'
  wdqs_director_ldf:
    backends:
      eqiad: 'wdqs1005.eqiad.wmnet'
  ores:
    be_opts:
      port: 8081
    backends:
      eqiad: 'ores.svc.eqiad.wmnet'
      codfw: 'ores.svc.codfw.wmnet'
cache::req_handling:
  cxserver.wikimedia.org:
    director: 'cxserver_backend'
    caching: 'pass'
  default:
    director: 'appservers'
    debug_director: 'appservers_debug'
    subpaths:
      '^/api/rest_v1/':
        director: 'restbase_backend'
      '^/w/api\.php':
        director: 'api'
        debug_director: 'appservers_debug'
cache::fe_transient_gb: 5
cache::be_transient_gb: 2
# Profile::cache::base
profile::cache::base::zero_site: 'https://zero.wikimedia.org'
profile::cache::base::purge_host_only_upload_re: '^(upload|maps)\.wikimedia\.org$'
profile::cache::base::purge_host_not_upload_re: '^(?!(upload|maps)\.wikimedia\.org)'
profile::cache::base::storage_parts: ['sda3', 'sdb3']
profile::cache::base::purge_host_regex: ''
profile::cache::base::purge_multicasts: ['239.128.0.112']
profile::cache::base::purge_varnishes: ['127.0.0.1:3128', '127.0.0.1:3127']
profile::cache::base::fe_runtime_params:
    - default_ttl=86400
    - gethdr_extrachance=0
profile::cache::base::be_runtime_params:
    - default_ttl=86400
    - timeout_idle=120
    - nuke_limit=1000
    - lru_interval=31
    - gethdr_extrachance=0
# Profile::cache::ssl::unified
profile::cache::ssl::unified::monitoring: true
profile::cache::ssl::unified::letsencrypt: false

# Enable varnishkafka-* instance monitoring.
profile::cache::kafka::webrequest::monitoring_enabled: true
profile::cache::kafka::eventlogging::monitoring_enabled: true
profile::cache::kafka::statsv::monitoring_enabled: true

profile::cache::kafka::webrequest::kafka_cluster_name: jumbo-eqiad
profile::cache::kafka::webrequest::ssl_enabled: true

# This should match an entry in the kafka_clusters hash (defined in common.yaml).
# We use the fully qualified kafka cluster name (with datacenter), because we want
# to route all statsv -> statsd traffic to the datacenter that hosts the master
# statsd instance.  If the active statsd instance changes to codfw (for an extended period of time)
# should probably change this to main-codfw.  If you don't things will probably be fine,
# but statsv will have to send messages over UDP cross-DC to the active statsd instance.
profile::cache::kafka::statsv::kafka_cluster_name: main-eqiad

# Monitor varnishkafka-eventlogging process.
profile::cache::kafka::eventlogging::monitoring_enabled: true
profile::cache::kafka::eventlogging::kafka_cluster_name: jumbo-eqiad
profile::cache::kafka::eventlogging::ssl_enabled: true
