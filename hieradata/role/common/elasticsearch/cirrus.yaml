# General configs
cluster: elasticsearch
admin::groups:
  - elasticsearch-roots

# T130329
profile::base::check_disk_options: -w 15% -c 10% -W 6% -K 3% -l -e -A -i "/srv/sd[a-b][1-3]" --exclude-type=tracefs

profile::elasticsearch::version: '5.6'
profile::elasticsearch::cirrus::storage_device: md1
profile::elasticsearch::cirrus::ferm_srange: '$DOMAIN_NETWORKS'
profile::elasticsearch::base_data_dir: /srv/elasticsearch
profile::elasticsearch::common_settings:
    awareness_attributes: 'row'
    # We need these plugins to be loaded in order to work properly. This will keep
    # elasticsearch from starting if these plugins are not available.
    plugins_mandatory:
      - analysis-hebrew
      - analysis-icu
      - analysis-smartcn
      - analysis-stconvert
      - analysis-stempel
      - analysis-ukrainian
      - experimental-highlighter
      - extra
      - extra-analysis-esperanto
      - extra-analysis-serbian
      - extra-analysis-slovak
      - ltr

    # More than 30G isn't very useful
    heap_memory: '30G'

    # Don't run if more than 1 master missing
    minimum_master_nodes: 2

    # wait that long for all nodes to restart. If not all nodes are present after
    # `recover_after_time`, recover anyway, as long as at least
    # `recover_after_nodes` are present.
    recover_after_time: '5m'

    # mwgrep queries one copy of each shard in the cluster, which is currently
    # just over 3k shards. For it to work we need to increase the limit from
    # default 1k
    search_shard_count_limit: 5000

    # Increase the per-node cache for compiled LTR models from default 10MB
    ltr_cache_size: '100mb'

    # Let apifeatureusage create their indices
    auto_create_index: '+apifeatureusage-*,-*'

    script_max_compilations_per_minute: 10000
    bulk_thread_pool_executors: 6
    bulk_thread_pool_capacity: 1000
    filter_cache_size: '20%'

# Msearch daemons read same topic in same consumer group in all dcs. They
# toggle themselves on/off based on load of the local elasticsearch cluster.
profile::mjolnir::kafka_msearch_daemon::kafka_cluster: jumbo-eqiad
profile::mjolnir::kafka_msearch_daemon::input_topic: mjolnir.msearch-prod-request
profile::mjolnir::kafka_msearch_daemon::output_topic: mjolnir.msearch-prod-response
# Max concurrent search threads consumed is:
#   # kafka partitions * num_workers * max_concurrent_searches * # shards per index
#   = (35 * 2 * 2 * 7)
#   = max 980 concurrent shard searches
# Unfortunately # shards per index is variable, so some caution is still required.
profile::mjolnir::kafka_msearch_daemon::num_workers: 2
profile::mjolnir::kafka_msearch_daemon::max_concurrent_searches: 2

# Bulk daemon consumes per-datacenter to apply page updates to all clusters.
profile::mjolnir::kafka_bulk_daemon::kafka_cluster: "main-%{::site}"
profile::mjolnir::kafka_bulk_daemon::group_id: "cirrussearch_updates_%{::site}"
profile::mjolnir::kafka_bulk_daemon::topics:
  - eqiad.cirrussearch.page-index-update
  - codfw.cirrussearch.page-index-update
diamond::remove: true
