nagios_group: analytics_eqiad
cluster: analytics
admin::groups:
  - analytics-admins

profile::hadoop::common::hadoop_cluster_name: 'analytics-hadoop'

profile::oozie::client::oozie_host: 'an-coord1001.eqiad.wmnet'

# Set the hive-site.xml file with group ownership 'analytics' so systemd timers
# can read the file.
profile::hive::client::config_files_group_ownership: 'analytics'

profile::analytics::cluster::hdfs_mount::monitoring_user: 'analytics'

# Hive Client settings.
# Hive configuration is common to multiple clients, but because of role based
# hiera lookups, we need to repeat it in multiple places. If you change this,
# make sure you change it in all the right places!
profile::hive::client::server_host: an-coord1001.eqiad.wmnet
profile::hive::client::server_port: 10000
profile::hive::client::metastore_host: 'an-coord1001.eqiad.wmnet'

# Hive Server Settings
profile::hive::server::monitoring_enabled: true
profile::hive::server::ferm_srange: '$ANALYTICS_NETWORKS'
profile::hive::metastore::monitoring_enabled: true
profile::hive::metastore::ferm_srange: '$ANALYTICS_NETWORKS'

# Presto (Coordinator) Server settings
profile::presto::monitoring_enabled: true
profile::presto::use_kerberos: true
profile::presto::cluster_name: analytics-presto
profile::presto::discovery_uri: https://an-coord1001.eqiad.wmnet:8281
profile::presto::server::heap_max: 4G
profile::presto::server::config_properties:
  coordinator: true
  node-scheduler.include-coordinator: false
  discovery-server.enabled: true
  # Set network-topology to legacy since we are not (yet?) running
  # presto co-located with HDFS nodes. If we were, we would
  # set this to 'flat'.
  node-scheduler.network-topology: legacy
  http-server.authentication.type: 'KERBEROS'
  http.server.authentication.krb5.service-name: 'presto'
  http.server.authentication.krb5.keytab: '/etc/security/keytabs/presto/presto.keytab'
  http.authentication.krb5.config: '/etc/krb5.conf'
profile::presto::server::catalogs:
  # Each catalog hash should contain a single properties has that will
  # end up being passed to the presto::properties define.  This will render
  # a properties file at /etc/presto/catalog/$name.properties.
  analytics_hive:
    properties:
      connector.name: hive-hadoop2
      hive.security: read-only
      # Add Hadoop config files so Hive connector can work with HA Hadoop NameNodes.
      hive.config.resources: /etc/hadoop/conf/core-site.xml,/etc/hadoop/conf/hdfs-site.xml
      hive.metastore.uri: thrift://an-coord1001.eqiad.wmnet:9083
      hive.metastore.username: presto
      hive.storage-format: PARQUET
      hive.compression-codec: SNAPPY
      # We do not (yet) colocate workers with Hadoop DataNodes.
      hive.force-local-scheduling: false
      # Allow presto-cli to impersonate the user running the process
      hive.hdfs.impersonation.enabled: true
      # TODO: do we want to disable non managed tables?
      hive.non-managed-table-writes-enabled: true
      hive.non-managed-table-creates-enabled: true
      hive.metastore.authentication.type: 'KERBEROS'
      hive.metastore.service.principal: 'hive/an-coord1001.eqiad.wmnet@WIKIMEDIA'
      hive.metastore.client.principal: 'presto/an-coord1001.eqiad.wmnet@WIKIMEDIA'
      hive.metastore.client.keytab: '/etc/security/keytabs/presto/presto.keytab'
      hive.hdfs.authentication.type: 'KERBEROS'
      hive.hdfs.impersonation.enabled: true
      hive.hdfs.presto.principal: 'presto/an-coord1001.eqiad.wmnet@WIKIMEDIA'
      hive.hdfs.presto.keytab: '/etc/security/keytabs/presto/presto.keytab'
      hive.hdfs.wire-encryption.enabled: true
      hive.parquet.fail-on-corrupted-statistics: false
profile::presto::server::ferm_srange: $ANALYTICS_NETWORKS


profile::analytics::database::meta::monitoring_enabled: true
profile::analytics::database::meta::ferm_srange: '(($DRUID_PUBLIC_HOSTS $ANALYTICS_NETWORKS (@resolve((db1108.eqiad.wmnet)) @resolve((db1108.eqiad.wmnet), AAAA))))'

profile::analytics::refinery::job::data_purge::public_druid_host: 'druid1004.eqiad.wmnet'
profile::analytics::refinery::job::data_check::ensure_timers: 'absent'
profile::analytics::refinery::job::refine::ensure_timers: 'absent'
profile::analytics::refinery::job::camus::ensure_timers: 'absent'
profile::analytics::refinery::job::hdfs_cleaner::ensure_timer: 'absent'
profile::analytics::refinery::job::project_namespace_map::ensure_timer: 'absent'
profile::analytics::refinery::job::sqoop_mediawiki::ensure_timers: 'absent'
profile::analytics::refinery::job::druid_load::ensure_timers: 'absent'
profile::analytics::refinery::job::data_purge::ensure_timers: 'absent'

profile::oozie::server::monitoring_enabled: true
profile::oozie::server::ferm_srange: '$ANALYTICS_NETWORKS'

# Comment taken from profile::oozie::server:
#
# This is not currently working.  Disabling
# this allows any user to manage any Oozie
# job.  Since access to our cluster is limited,
# this isn't a big deal.  But, we should still
# figure out why this isn't working and
# turn it back on.
# I was not able to kill any oozie jobs
# with this on, even though the
# oozie.service.ProxyUserService.proxyuser.*
# settings look like they are properly configured.
profile::oozie::server::use_admins_list: true
profile::oozie::server::admin_users: ['otto', 'nuria', 'milimetric', 'mforns', 'fdans', 'joal', 'elukey', 'klausman', 'razzi']

# Following Cloudera recommandations for ~20 users
profile::hive::client::hive_metastore_opts: '-Xms4g -Xmx4g -XX:+UseG1GC -XX:+UseStringDeduplication -XX:MaxGCPauseMillis=1000 -Djava.net.preferIPv4Stack=false -javaagent:/usr/share/java/prometheus/jmx_prometheus_javaagent.jar=[::]:9183:/etc/prometheus/hive_metastore_jmx_exporter.yaml'
profile::hive::client::hive_server_opts: '-Xms8g -Xmx8g -XX:+UseG1GC -XX:+UseStringDeduplication -XX:MaxGCPauseMillis=1000 -Djava.net.preferIPv4Stack=false -javaagent:/usr/share/java/prometheus/jmx_prometheus_javaagent.jar=[::]:10100:/etc/prometheus/hive_server_jmx_exporter.yaml'
profile::oozie::server::jvm_opts: '-Xms2g -Xmx2g'

# Build and install oozie sharelib for our custom spark2 package.
profile::hadoop::spark2::install_oozie_sharelib: true

# Upload the spark2-assembly.zip file to HDFS
profile::hadoop::spark2::install_assembly: true

profile::analytics::refinery::job::camus::monitoring_enabled: true

# Http proxy to get project-namespace infos from API using python
profile::analytics::refinery::job::project_namespace_map::http_proxy: 'http://webproxy.eqiad.wmnet:8080'

profile::base::debdeploy::exclude_mounts:
  - /mnt/hdfs

profile::analytics::refinery::job::refine::use_kerberos: true
profile::analytics::refinery::job::data_purge::use_kerberos: true
profile::analytics::cluster::hdfs_mount::kerberos_enabled: true
profile::hadoop::balancer::ensure: 'absent'
profile::oozie::server::use_kerberos: true
profile::hive::server::use_kerberos: true
profile::hadoop::spark2::use_kerberos: true
profile::analytics::refinery::job::camus::use_kerberos: true
profile::hive::client::hive_metastore_sasl_enabled: true
profile::hive::client::hive_metastore_kerberos_keytab_file: '/etc/security/keytabs/hive/hive.keytab'
profile::hive::client::hive_metastore_kerberos_principal: 'hive/_HOST@WIKIMEDIA'
profile::hive::client::hive_server2_authentication: 'KERBEROS'
profile::hive::client::hive_server2_authentication_kerberos_principal: 'hive/_HOST@WIKIMEDIA'
profile::hive::client::hive_server2_authentication_kerberos_keytab: '/etc/security/keytabs/hive/hive.keytab'
profile::oozie::server::oozie_service_kerberos_enabled: true
profile::oozie::server::local_realm: 'ANALYTICS.EQIAD.WMFLABS'
profile::oozie::server::oozie_service_keytab_file: '/etc/security/keytabs/oozie/HTTP-oozie.keytab'
profile::oozie::server::oozie_service_kerberos_principal: 'oozie/_HOST@WIKIMEDIA'
profile::oozie::server::oozie_authentication_type: 'kerberos'
profile::oozie::server::oozie_authentication_kerberos_principal: 'HTTP/_HOST@WIKIMEDIA'
profile::oozie::server::spark_defaults_config_dir: '/etc/spark2/conf'

profile::kerberos::keytabs::keytabs_metadata:
  - role: 'hive'
    owner: 'hive'
    group: 'hive'
    filename: 'hive.keytab'
  - role: 'oozie'
    owner: 'oozie'
    group: 'oozie'
    filename: 'HTTP-oozie.keytab'
  - role: 'analytics'
    owner: 'analytics'
    group: 'analytics'
    filename: 'analytics.keytab'
  - role: 'hadoop'
    owner: 'hdfs'
    group: 'hdfs'
    filename: 'hdfs.keytab'
    parent_dir_grp: 'hadoop'
  - role: 'presto'
    owner: 'presto'
    group: 'presto'
    filename: 'presto.keytab'

profile::java::java_packages:
  - version: '8'
    variant: 'jdk'
profile::java::extra_args: 'JAVA_TOOL_OPTIONS="-Dfile.encoding=UTF-8"'