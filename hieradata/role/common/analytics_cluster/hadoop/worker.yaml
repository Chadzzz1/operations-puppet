nagios_group: analytics_eqiad
cluster: analytics

profile::standard::admin_groups:
  - analytics-admins
profile::standard::admin_groups_no_ssh:
  - analytics-privatedata-users
  # elasticsearch::analytics creates the analytics-search user and group
  # that analytics-search-users are allowed to sudo to.  This is used
  # for deploying files to HDFS.
  - analytics-search-users
  - gpu-users

profile::hadoop::common::hadoop_cluster_name: 'analytics-hadoop'

profile::hive::client::hive_service_name: 'analytics-hive'

# This is the setting for the default 12-disks hadoop worker
# More specific settings for other workers are in regex.yaml
profile::hadoop::common::min_datanode_mounts: 10

profile::hadoop::worker::monitoring_enabled: true

profile::base::linux419::enable: true

# Analytics worker disks are large.  We will install a custom
# NRPE check for them, so the base module's should ignore them.
profile::base::check_disk_options: '-w 6% -c 3% -W 6% -K 3% -l -e -A -i "/var/lib/hadoop/data" --exclude-type=tracefs'
profile::base::check_raid_policy: 'WriteBack'

profile::hadoop::worker::ferm_srange: '(($ANALYTICS_NETWORKS $DRUID_PUBLIC_HOSTS $LABSTORE_HOSTS))'

# Deploy TLS keys and xml configuration files
profile::hadoop::common::ensure_ssl_config: true

prometheus::node_exporter::collectors_extra:
  - meminfo_numa

profile::kerberos::keytabs::keytabs_metadata:
  - role: 'hadoop'
    owner: 'hdfs'
    group: 'hdfs'
    filename: 'hdfs.keytab'
    parent_dir_grp: 'hadoop'
  - role: 'hadoop'
    owner: 'yarn'
    group: 'yarn'
    filename: 'yarn.keytab'
    parent_dir_grp: 'hadoop'
  - role: 'hadoop'
    owner: 'hdfs'
    group: 'hdfs'
    filename: 'HTTP.keytab'
    parent_dir_grp: 'hadoop'

profile::java::java_packages:
  - version: '8'
    variant: 'jdk'
profile::java::extra_args: 'JAVA_TOOL_OPTIONS="-Dfile.encoding=UTF-8"'
