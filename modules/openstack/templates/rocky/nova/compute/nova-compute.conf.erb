[DEFAULT]
# Are these the same?
#compute_driver=nova.virt.libvirt.LibvirtDriver
compute_driver=libvirt.LibvirtDriver

# Ensure VMs have the same state after a host reboot
resume_guests_state_on_host_boot = True

# No plans to use ovs
# neutron_ovs_bridge=br-int

[libvirt]
virt_type=kvm
vif_driver=nova.virt.libvirt.vif.LibvirtGenericVIFDriver
use_virtio_for_bridges=true

# live_migration_bandwidth is documented in the code, and nowhere else.
# 'Maximum bandwidth to be used during migration, in Mbps'
# Limit this to around a third of available 1Gbps connection so we don't
# throttle running instances when migrating.
live_migration_bandwidth=300
live_migration_uri=qemu://%s.eqiad.wmnet/system?pkipath=/var/lib/nova

live_migration_completion_timeout=4000
<% if @enable_nova_rbd %>
# Ceph RBD ephemeral config
images_type = rbd
images_rbd_pool = <%= @ceph_rbd_pool %>
images_rbd_ceph_conf = /etc/ceph/ceph.conf
rbd_user = <%= @ceph_rbd_client_name %>
rbd_secret_uuid = <%= @libvirt_rbd_uuid %>
disk_cachemodes = "network=writeback"

# Define custom CPU restriction to the lowest
# common subset of features across all hypervisors.
# Until we decom cloudvirt1001-1009, this is Ivy Bridge.
cpu_mode=custom
cpu_model=IvyBridge-IBRS
<% end -%>
